{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import csv\n",
    "import time\n",
    "#np.load('calibration.pckl', allow_pickle=True)\n",
    "cameraMatrix = np.array([[1.68369547e+03, 0.00000000e+00, 9.62127588e+02],\n",
    " [0.00000000e+00, 1.68678723e+03, 5.27056802e+02],\n",
    " [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]);\n",
    "\n",
    "distCoeffs = np.array([[ 2.33791162e-01, -1.13102611e+00,  1.40999340e-03,  1.16345153e-03, 1.71214616e+00]]);\n",
    "\n",
    "np.save('cameraMatrix.npy', cameraMatrix) \n",
    "np.save('distCoeffs.npy', distCoeffs) \n",
    "\n",
    "np.load('cameraMatrix.npy');\n",
    "np.load('distCoeffs.npy');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) /Users/runner/work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:605: error: (-5:Bad argument) Rotation must be represented by 1x3 or 3x1 floating-point rotation vector, or 3x3 rotation matrix in function 'cvProjectPoints2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/89/grn8kspd2xnd37k5mt_w8xsm0000gn/T/ipykernel_97154/1058653275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# pass on the distortion and camera coefficients, and the marker size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_objPoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maruco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimatePoseSingleMarkers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkerSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistCoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maruco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawAxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistCoeffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) /Users/runner/work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:605: error: (-5:Bad argument) Rotation must be represented by 1x3 or 3x1 floating-point rotation vector, or 3x3 rotation matrix in function 'cvProjectPoints2Internal'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "markerSize = 0.1245\n",
    "f = open(\"robotPosition.csv\", \"a+\")\n",
    "writer = csv.writer(f, delimiter=',')\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    # img=cv2.resize(img,(w,h))\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Pick the AruCo marker \n",
    "    aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL)#DICT_4X4_250)\n",
    "    parameters = cv2.aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(imgGray, aruco_dict, parameters=parameters)\n",
    "    if type(ids) is np.ndarray:\n",
    "        # pass on the distortion and camera coefficients, and the marker size\n",
    "        rvecs, tvecs, _objPoints = cv2.aruco.estimatePoseSingleMarkers(corners, markerSize, cameraMatrix, distCoeffs)\n",
    "        cv2.aruco.drawAxis(img, cameraMatrix, distCoeffs, rvecs , tvecs, 0.1)\n",
    "        t = float(time.time())\n",
    "        data = [t, tvecs[0][0][0], tvecs[0][0][1], tvecs[0][0][2]]\n",
    "        writer.writerow(data)\n",
    "    f.flush()\n",
    "    cv2.imshow(\"Output\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.98289962"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[-59.12228991,  11.98289962, 174.31383505]]])\n",
    "a[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>accx</th>\n",
       "      <th>accY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  accx  accY\n",
       "0  1     1     1\n",
       "1  2     5     2\n",
       "2  3     6     4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'t': [1,2,3,4,5,5,6], 'accx': [1,5,6,7,7,3], 'accY': [1,2,4]}\n",
    "minLen = 10000000000000000000000\n",
    "for key in data:\n",
    "    valLen = len(data[key])\n",
    "    if valLen < minLen:\n",
    "        minLen = valLen\n",
    "for key in data:\n",
    "    data[key] = data[key][:minLen]\n",
    "#minimum = min(data_len)\n",
    "\n",
    "#print(len(data[\"t\"]))\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
